---
title: 'Initial clean of Samsung data'
author: 'Guy Maskall'
date: '`r format(Sys.time(), "%d %b, %Y")`'
---

# Introduction

The name of the game. We've been presented with some activity accelerometer
data. We wish to use summary statistics of the acceleration data, for example
mean and standard deviation. However we lack confidence that those summary
columns have been calculated correctly and this work seeks to validate this.
Furthermore, successful validation will enable us to derive these features
ourselves on future data.

Load the feature names.

```{r, load}
data_path <- '../uci_har_dataset/'
feature_names <- read_delim(
    file.path(data_path, 'features.txt'), " ", col_names=c("index", "name")
)
length(feature_names)
head(feature_names)
```

Some feature names are duplicated:

```{r, duplicated_feats}
feature_names %>%
    count(name) %>%
    filter(n > 1)
```

Three duplications. Is it always three? Three for X, Y, Z? Did someone forget
to add the axis??

```{r, dup_feats2}
feature_names %>%
    count(name) %>%
    filter(!(n %in% c(1, 3)))
```

Good, feature names only appear either 1 or 3 times. They're either unique or,
we suspect, for X, Y, and Z but unlabelled. Still cautious about this.

Load the training data.

X:

```{r, X_tr}
x_tr_file <- file.path(data_path, 'train', 'X_train.txt')
X_tr <- read_table(x_tr_file, col_names=F)
dim(X_tr)
```

Consider the duplications. Let's look at some examples.

```{r, dup_eg1}
dups <- which(feature_names$name == "fBodyAcc-bandsEnergy()-1,16")
X_tr[1:10, dups]
```



Y:

```{r, y_tr}
y_tr_file <- file.path(data_path, 'train', 'y_train.txt')
y_tr <- read_lines(y_tr_file)
length(y_tr)
```
